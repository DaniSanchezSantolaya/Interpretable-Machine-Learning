{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Program Files\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "C:\\Program Files\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train, labels_train, test, labels_test, verbose=True):\n",
    "    acc_train = sklearn.metrics.accuracy_score(labels_train, model.predict(train))\n",
    "    acc_test = sklearn.metrics.accuracy_score(labels_test, model.predict(test))\n",
    "    auc_train = sklearn.metrics.roc_auc_score(labels_train, model.predict(train))\n",
    "    auc_test = sklearn.metrics.roc_auc_score(labels_test, model.predict(test))\n",
    "    if verbose:\n",
    "        print(\"Train Accuracy: \" + \"{:.3f}\".format(acc_train) + \" - Train AUC: \" + \"{:.3f}\".format(auc_train))\n",
    "        print(\"Test  Accuracy: \" + \"{:.3f}\".format(acc_test) + \" - Test AUC: \" + \"{:.3f}\".format(auc_test))\n",
    "    return acc_train, auc_train, acc_test, auc_test\n",
    "\n",
    "def obtain_explanations(explainer, model, X, feature_names):\n",
    "    # Explaining all predictions\n",
    "    explanations = np.zeros((X.shape[0], X.shape[1]))\n",
    "    exp_scores = []\n",
    "    for i in range(len(X)):\n",
    "        exp = explainer.explain_instance(X[i], model.predict_proba, num_features=len(feature_names), top_labels=1)\n",
    "        key_label = [*exp.as_map()][0]\n",
    "        for feature_exp in exp.as_map()[key_label]:\n",
    "            feature_idx = feature_exp[0]\n",
    "            feature_val = feature_exp[1]\n",
    "            explanations[i, feature_idx] = feature_val\n",
    "        #if i % 100 == 0:\n",
    "        exp_scores.append(exp.score)\n",
    "            #print(i)\n",
    "            \n",
    "    return explanations, exp_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = sklearn.datasets.make_classification(n_samples=5000, \n",
    "                                     n_features=20, \n",
    "                                     n_informative=20, \n",
    "                                     n_redundant=0, \n",
    "                                     n_repeated=0, \n",
    "                                     n_classes=2, \n",
    "                                     n_clusters_per_class=2, \n",
    "                                     weights=None, \n",
    "                                     flip_y=0.02, \n",
    "                                     class_sep=1.0, \n",
    "                                     hypercube=True, \n",
    "                                     shift=0.0, \n",
    "                                     scale=1.0, \n",
    "                                     shuffle=True, \n",
    "                                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-61215eca99ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'feature_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'label_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Split dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "feature_names = ['feature_' + str(i) for i in range(data.shape[1])]\n",
    "target_names = ['label_1']\n",
    "\n",
    "# Split dataset\n",
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data, labels, train_size=0.80)\n",
    "print('Num training samples: ' + str(len(train)))\n",
    "print('Num test samples: ' + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train4.csv\", train, delimiter=\",\")\n",
    "np.savetxt(\"test4.csv\", test, delimiter=\",\")\n",
    "np.savetxt(\"labels_train4.csv\", labels_train, delimiter=\",\")\n",
    "np.savetxt(\"labels_test4.csv\", labels_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to load the csv instead of creating it\n",
    "train = np.genfromtxt(\"train4.csv\", delimiter=',')\n",
    "test = np.genfromtxt(\"test4.csv\", delimiter=',')\n",
    "labels_train = np.genfromtxt(\"labels_train4.csv\", delimiter=',')\n",
    "labels_test = np.genfromtxt(\"labels_test4.csv\", delimiter=',')\n",
    "\n",
    "feature_names = ['feature_' + str(i) for i in range(train.shape[1])]\n",
    "target_names = ['label_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://math.stackexchange.com/questions/889425/what-does-determinant-of-covariance-matrix-give\n",
    "\n",
    "https://stats.stackexchange.com/questions/225434/a-measure-of-variance-from-the-covariance-matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with  2  features\n",
      "[[0, 1], [0, 1]]\n",
      "auc_train mean:  0.56425\n",
      "auc_test mean:  0.593\n",
      "trace mean:  0.004900036894587331\n",
      "trace_normalized mean:  0.0024500184472936656\n",
      "median trace_normalized:  0.0024500184472936656\n",
      "mean max_eigenvalue:  0.0045611539263340235\n",
      "explanation fit:  0.3376164902949421\n",
      "-----------------------------\n",
      "Starting with  3  features\n",
      "[[0, 1, 2], [0, 1, 2]]\n",
      "auc_train mean:  0.6075\n",
      "auc_test mean:  0.615\n",
      "trace mean:  0.02079442316701109\n",
      "trace_normalized mean:  0.0069314743890036955\n",
      "median trace_normalized:  0.0069314743890036955\n",
      "mean max_eigenvalue:  0.015057045235209829\n",
      "explanation fit:  0.3270525146981462\n",
      "-----------------------------\n",
      "Starting with  4  features\n",
      "[[0, 1, 2, 3], [0, 1, 2, 3]]\n",
      "auc_train mean:  0.64175\n",
      "auc_test mean:  0.624\n",
      "trace mean:  0.035251420118251095\n",
      "trace_normalized mean:  0.008812855029562774\n",
      "median trace_normalized:  0.008812855029562774\n",
      "mean max_eigenvalue:  0.01614815154289502\n",
      "explanation fit:  0.32108197699527374\n",
      "-----------------------------\n",
      "Starting with  5  features\n",
      "[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n",
      "auc_train mean:  0.64025\n",
      "auc_test mean:  0.636\n",
      "trace mean:  0.03666586712080169\n",
      "trace_normalized mean:  0.007333173424160339\n",
      "median trace_normalized:  0.007333173424160339\n",
      "mean max_eigenvalue:  0.015869080276025536\n",
      "explanation fit:  0.31562004183057085\n",
      "-----------------------------\n",
      "Starting with  6  features\n",
      "[[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]]\n",
      "auc_train mean:  0.66725\n",
      "auc_test mean:  0.656\n",
      "trace mean:  0.06555449226816387\n",
      "trace_normalized mean:  0.010925748711360645\n",
      "median trace_normalized:  0.010925748711360645\n",
      "mean max_eigenvalue:  0.025963535115137753\n",
      "explanation fit:  0.30975724102724006\n",
      "-----------------------------\n",
      "Starting with  7  features\n",
      "[[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]\n",
      "auc_train mean:  0.6805\n",
      "auc_test mean:  0.681\n",
      "trace mean:  0.0667359271447176\n",
      "trace_normalized mean:  0.0095337038778168\n",
      "median trace_normalized:  0.0095337038778168\n",
      "mean max_eigenvalue:  0.023936771854111073\n",
      "explanation fit:  0.3080195078986183\n",
      "-----------------------------\n",
      "Starting with  8  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]]\n",
      "auc_train mean:  0.69675\n",
      "auc_test mean:  0.704\n",
      "trace mean:  0.08368714671715903\n",
      "trace_normalized mean:  0.010460893339644879\n",
      "median trace_normalized:  0.010460893339644879\n",
      "mean max_eigenvalue:  0.029086719308271433\n",
      "explanation fit:  0.3017367293815658\n",
      "-----------------------------\n",
      "Starting with  9  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8], [0, 1, 2, 3, 4, 5, 6, 7, 8]]\n",
      "auc_train mean:  0.7015\n",
      "auc_test mean:  0.705\n",
      "trace mean:  0.09017330638635573\n",
      "trace_normalized mean:  0.010019256265150638\n",
      "median trace_normalized:  0.010019256265150638\n",
      "mean max_eigenvalue:  0.03044258333109541\n",
      "explanation fit:  0.29920298953704455\n",
      "-----------------------------\n",
      "Starting with  10  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
      "auc_train mean:  0.70175\n",
      "auc_test mean:  0.704\n",
      "trace mean:  0.09117884592560421\n",
      "trace_normalized mean:  0.00911788459256042\n",
      "median trace_normalized:  0.00911788459256042\n",
      "mean max_eigenvalue:  0.031096458919353726\n",
      "explanation fit:  0.2979942784789469\n",
      "-----------------------------\n",
      "Starting with  11  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
      "auc_train mean:  0.70025\n",
      "auc_test mean:  0.707\n",
      "trace mean:  0.09147091909482499\n",
      "trace_normalized mean:  0.008315538099529545\n",
      "median trace_normalized:  0.008315538099529545\n",
      "mean max_eigenvalue:  0.031231909313225413\n",
      "explanation fit:  0.2971398472139687\n",
      "-----------------------------\n",
      "Starting with  12  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n",
      "auc_train mean:  0.71775\n",
      "auc_test mean:  0.71\n",
      "trace mean:  0.10158078920086652\n",
      "trace_normalized mean:  0.008465065766738878\n",
      "median trace_normalized:  0.008465065766738878\n",
      "mean max_eigenvalue:  0.03491016533228819\n",
      "explanation fit:  0.29306067444608774\n",
      "-----------------------------\n",
      "Starting with  13  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]\n",
      "auc_train mean:  0.75725\n",
      "auc_test mean:  0.736\n",
      "trace mean:  0.10919057694742487\n",
      "trace_normalized mean:  0.008399275149801913\n",
      "median trace_normalized:  0.008399275149801913\n",
      "mean max_eigenvalue:  0.027249170759401663\n",
      "explanation fit:  0.28863718587386267\n",
      "-----------------------------\n",
      "Starting with  14  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]]\n",
      "auc_train mean:  0.80925\n",
      "auc_test mean:  0.801\n",
      "trace mean:  0.14466205738658033\n",
      "trace_normalized mean:  0.010333004099041454\n",
      "median trace_normalized:  0.010333004099041454\n",
      "mean max_eigenvalue:  0.04950023367672363\n",
      "explanation fit:  0.2795376195396678\n",
      "-----------------------------\n",
      "Starting with  15  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]\n",
      "auc_train mean:  0.82525\n",
      "auc_test mean:  0.808\n",
      "trace mean:  0.15495310612791416\n",
      "trace_normalized mean:  0.010330207075194277\n",
      "median trace_normalized:  0.010330207075194277\n",
      "mean max_eigenvalue:  0.048315581418212405\n",
      "explanation fit:  0.2741929836487202\n",
      "-----------------------------\n",
      "Starting with  16  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
      "auc_train mean:  0.8245\n",
      "auc_test mean:  0.807\n",
      "trace mean:  0.15645640683028508\n",
      "trace_normalized mean:  0.009778525426892818\n",
      "median trace_normalized:  0.009778525426892818\n",
      "mean max_eigenvalue:  0.04769343894251506\n",
      "explanation fit:  0.27378505034867107\n",
      "-----------------------------\n",
      "Starting with  17  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]]\n",
      "auc_train mean:  0.84525\n",
      "auc_test mean:  0.823\n",
      "trace mean:  0.16826104932636285\n",
      "trace_normalized mean:  0.009897708783903697\n",
      "median trace_normalized:  0.009897708783903697\n",
      "mean max_eigenvalue:  0.04943048128734012\n",
      "explanation fit:  0.2700427493276053\n",
      "-----------------------------\n",
      "Starting with  18  features\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n",
      "auc_train mean:  0.846\n",
      "auc_test mean:  0.823\n",
      "trace mean:  0.1681793765025896\n",
      "trace_normalized mean:  0.00934329869458831\n",
      "median trace_normalized:  0.00934329869458831\n",
      "mean max_eigenvalue:  0.04932483663238209\n",
      "explanation fit:  0.2697017817597881\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "features_to_use = [[0,1],\n",
    "                  [0,1,2],\n",
    "                  [0,1,2,3],\n",
    "                  [0,1,2,3,4],\n",
    "                  [0,1,2,3,4,5],\n",
    "                  [0,1,2,3,4,5,6],\n",
    "                  [0,1,2,3,4,5,6,7],\n",
    "                  [0,1,2,3,4,5,6,7,8],\n",
    "                  [0,1,2,3,4,5,6,7,8,9],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11,12,13],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\n",
    "                  [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],\n",
    "                  ]\n",
    "\n",
    "l_repetitions = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2 ,2, 2]\n",
    "results_lr = {}\n",
    "\n",
    "\n",
    "for i in range(len(features_to_use)):\n",
    "    n_features = len(features_to_use[i])\n",
    "    n_reps = l_repetitions[i]\n",
    "    print('Starting with ', n_features, ' features')\n",
    "    results_lr[n_features] = {}\n",
    "    results_lr[n_features]['trace'] = []\n",
    "    results_lr[n_features]['trace_normalized'] = []\n",
    "    results_lr[n_features]['determinant'] = []\n",
    "    results_lr[n_features]['determinant_normalized'] = []\n",
    "    results_lr[n_features]['auc_train'] = []\n",
    "    results_lr[n_features]['auc_test'] = []\n",
    "    results_lr[n_features]['used_features'] = []\n",
    "    results_lr[n_features]['max_eigenvalue'] = []\n",
    "    results_lr[n_features]['explanation_fit'] = []\n",
    "    \n",
    "    for j in range(n_reps):\n",
    "        # Pick n_features randomly\n",
    "        idx_features = features_to_use[i]\n",
    "        f_names = list(np.array(feature_names)[idx_features])\n",
    "        results_lr[n_features]['used_features'].append(idx_features)\n",
    "        \n",
    "        model = linear_model.LogisticRegression(C=1)\n",
    "        model.fit(train[:,idx_features], labels_train)\n",
    "        #print(\"Model intercept: \", model.intercept_)\n",
    "        acc_train, auc_train, acc_test, auc_test = evaluate_model(model, train[:,idx_features], labels_train, test[:,idx_features], labels_test, verbose=False)\n",
    "        results_lr[n_features]['auc_train'].append(acc_train)\n",
    "        results_lr[n_features]['auc_test'].append(acc_test)\n",
    "\n",
    "        # Create explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(train[:,idx_features], feature_names=f_names, class_names=target_names, discretize_continuous=True)\n",
    "\n",
    "        # Explaining all samples\n",
    "        explanations_test, exp_score = obtain_explanations(explainer, model, test[:,idx_features], f_names)\n",
    "        np.savetxt(\"explanations_data/explanations_lr_\" + str(n_features) + \"_\" + str(j)  + \".csv\", explanations_test, delimiter=\",\")\n",
    "        results_lr[n_features]['explanation_fit'].append(np.mean(exp_score))\n",
    "        \n",
    "        # Compute covariance matrix of Explanations datasets.\n",
    "        cov_matrix_test = np.cov(explanations_test, rowvar=False)\n",
    "        np.savetxt(\"results/cov_lr_\" + str(n_features) + \"_\" + str(j)  + \".csv\", cov_matrix_test, delimiter=\",\")\n",
    "\n",
    "        # Trace of covariance matrix\n",
    "        results_lr[n_features]['trace'].append(np.trace(cov_matrix_test))\n",
    "        results_lr[n_features]['trace_normalized'].append(np.trace(cov_matrix_test)/cov_matrix_test.shape[0])\n",
    "        results_lr[n_features]['determinant'].append(np.linalg.det(cov_matrix_test))\n",
    "        results_lr[n_features]['determinant_normalized'].append(np.linalg.det(cov_matrix_test)/cov_matrix_test.shape[0])\n",
    "        \n",
    "        # max-eigenvalues\n",
    "        eigen_val, eigen_vectors = np.linalg.eig(cov_matrix_test)\n",
    "        results_lr[n_features]['max_eigenvalue'].append(np.max(eigen_val))\n",
    "\n",
    "    print(results_lr[n_features]['used_features'])\n",
    "    print('auc_train mean: ', np.mean(results_lr[n_features]['auc_train']))\n",
    "    print('auc_test mean: ', np.mean(results_lr[n_features]['auc_test']))\n",
    "    print('trace mean: ', np.mean(results_lr[n_features]['trace']))\n",
    "    print('trace_normalized mean: ', np.mean(results_lr[n_features]['trace_normalized']))\n",
    "    print('median trace_normalized: ', np.median(results_lr[n_features]['trace_normalized']))\n",
    "    print('mean max_eigenvalue: ', np.mean(results_lr[n_features]['max_eigenvalue']))\n",
    "    print('explanation fit: ', np.mean(results_lr[n_features]['explanation_fit']))\n",
    "    print('-----------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df and save csv\n",
    "model_names = ['LR - ' + str(k) for k in results_lr.keys()]\n",
    "mean_auc_train = [np.mean(results_lr[k]['auc_train']) for k in results_lr.keys()]\n",
    "mean_auc_test = [np.mean(results_lr[k]['auc_test']) for k in results_lr.keys()]\n",
    "mean_trace = [np.mean(results_lr[k]['trace']) for k in results_lr.keys()]\n",
    "median_trace = [np.median(results_lr[k]['trace']) for k in results_lr.keys()]\n",
    "mean_trace_norm = [np.mean(results_lr[k]['trace_normalized']) for k in results_lr.keys()]\n",
    "mean_max_eig = [np.mean(results_lr[k]['max_eigenvalue']) for k in results_lr.keys()]\n",
    "median_max_eig = [np.median(results_lr[k]['max_eigenvalue']) for k in results_lr.keys()]\n",
    "mean_explanation_fit = [np.mean(results_lr[k]['explanation_fit']) for k in results_lr.keys()]\n",
    "median_explanation_fit = [np.median(results_lr[k]['explanation_fit']) for k in results_lr.keys()]\n",
    "\n",
    "df_results_lr = pd.DataFrame()\n",
    "df_results_lr['model_name'] = model_names\n",
    "df_results_lr['auc_train'] = mean_auc_train\n",
    "df_results_lr['auc_test'] = mean_auc_test\n",
    "df_results_lr['mean_trace'] = mean_trace\n",
    "df_results_lr['median_trace'] = median_trace\n",
    "df_results_lr['trace_norm'] = mean_trace_norm\n",
    "df_results_lr['mean_max_eig'] = mean_max_eig\n",
    "df_results_lr['median_max_eig'] = median_max_eig\n",
    "df_results_lr['mean_explanation_fit'] = mean_explanation_fit\n",
    "df_results_lr['median_explanation_fit'] = median_explanation_fit\n",
    "df_results_lr.to_csv('df_results_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>mean_trace</th>\n",
       "      <th>median_trace</th>\n",
       "      <th>trace_norm</th>\n",
       "      <th>mean_max_eig</th>\n",
       "      <th>median_max_eig</th>\n",
       "      <th>mean_explanation_fit</th>\n",
       "      <th>median_explanation_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR - 2</td>\n",
       "      <td>0.56425</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.337616</td>\n",
       "      <td>0.337616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR - 3</td>\n",
       "      <td>0.60750</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.327053</td>\n",
       "      <td>0.327053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR - 4</td>\n",
       "      <td>0.64175</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.321082</td>\n",
       "      <td>0.321082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR - 5</td>\n",
       "      <td>0.64025</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.315620</td>\n",
       "      <td>0.315620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR - 6</td>\n",
       "      <td>0.66725</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.065554</td>\n",
       "      <td>0.065554</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.309757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR - 7</td>\n",
       "      <td>0.68050</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.066736</td>\n",
       "      <td>0.066736</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.308020</td>\n",
       "      <td>0.308020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR - 8</td>\n",
       "      <td>0.69675</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.083687</td>\n",
       "      <td>0.083687</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.301737</td>\n",
       "      <td>0.301737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR - 9</td>\n",
       "      <td>0.70150</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.090173</td>\n",
       "      <td>0.090173</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.299203</td>\n",
       "      <td>0.299203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR - 10</td>\n",
       "      <td>0.70175</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.091179</td>\n",
       "      <td>0.091179</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.031096</td>\n",
       "      <td>0.031096</td>\n",
       "      <td>0.297994</td>\n",
       "      <td>0.297994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR - 11</td>\n",
       "      <td>0.70025</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.091471</td>\n",
       "      <td>0.091471</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.297140</td>\n",
       "      <td>0.297140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR - 12</td>\n",
       "      <td>0.71775</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.101581</td>\n",
       "      <td>0.101581</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.034910</td>\n",
       "      <td>0.034910</td>\n",
       "      <td>0.293061</td>\n",
       "      <td>0.293061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR - 13</td>\n",
       "      <td>0.75725</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.109191</td>\n",
       "      <td>0.109191</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.027249</td>\n",
       "      <td>0.027249</td>\n",
       "      <td>0.288637</td>\n",
       "      <td>0.288637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR - 14</td>\n",
       "      <td>0.80925</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.144662</td>\n",
       "      <td>0.144662</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.279538</td>\n",
       "      <td>0.279538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR - 15</td>\n",
       "      <td>0.82525</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.274193</td>\n",
       "      <td>0.274193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR - 16</td>\n",
       "      <td>0.82450</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.047693</td>\n",
       "      <td>0.047693</td>\n",
       "      <td>0.273785</td>\n",
       "      <td>0.273785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR - 17</td>\n",
       "      <td>0.84525</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.168261</td>\n",
       "      <td>0.168261</td>\n",
       "      <td>0.009898</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>0.270043</td>\n",
       "      <td>0.270043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR - 18</td>\n",
       "      <td>0.84600</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.168179</td>\n",
       "      <td>0.168179</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.049325</td>\n",
       "      <td>0.049325</td>\n",
       "      <td>0.269702</td>\n",
       "      <td>0.269702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  auc_train  auc_test  mean_trace  median_trace  trace_norm  \\\n",
       "0      LR - 2    0.56425     0.593    0.004900      0.004900    0.002450   \n",
       "1      LR - 3    0.60750     0.615    0.020794      0.020794    0.006931   \n",
       "2      LR - 4    0.64175     0.624    0.035251      0.035251    0.008813   \n",
       "3      LR - 5    0.64025     0.636    0.036666      0.036666    0.007333   \n",
       "4      LR - 6    0.66725     0.656    0.065554      0.065554    0.010926   \n",
       "5      LR - 7    0.68050     0.681    0.066736      0.066736    0.009534   \n",
       "6      LR - 8    0.69675     0.704    0.083687      0.083687    0.010461   \n",
       "7      LR - 9    0.70150     0.705    0.090173      0.090173    0.010019   \n",
       "8     LR - 10    0.70175     0.704    0.091179      0.091179    0.009118   \n",
       "9     LR - 11    0.70025     0.707    0.091471      0.091471    0.008316   \n",
       "10    LR - 12    0.71775     0.710    0.101581      0.101581    0.008465   \n",
       "11    LR - 13    0.75725     0.736    0.109191      0.109191    0.008399   \n",
       "12    LR - 14    0.80925     0.801    0.144662      0.144662    0.010333   \n",
       "13    LR - 15    0.82525     0.808    0.154953      0.154953    0.010330   \n",
       "14    LR - 16    0.82450     0.807    0.156456      0.156456    0.009779   \n",
       "15    LR - 17    0.84525     0.823    0.168261      0.168261    0.009898   \n",
       "16    LR - 18    0.84600     0.823    0.168179      0.168179    0.009343   \n",
       "\n",
       "    mean_max_eig  median_max_eig  mean_explanation_fit  median_explanation_fit  \n",
       "0       0.004561        0.004561              0.337616                0.337616  \n",
       "1       0.015057        0.015057              0.327053                0.327053  \n",
       "2       0.016148        0.016148              0.321082                0.321082  \n",
       "3       0.015869        0.015869              0.315620                0.315620  \n",
       "4       0.025964        0.025964              0.309757                0.309757  \n",
       "5       0.023937        0.023937              0.308020                0.308020  \n",
       "6       0.029087        0.029087              0.301737                0.301737  \n",
       "7       0.030443        0.030443              0.299203                0.299203  \n",
       "8       0.031096        0.031096              0.297994                0.297994  \n",
       "9       0.031232        0.031232              0.297140                0.297140  \n",
       "10      0.034910        0.034910              0.293061                0.293061  \n",
       "11      0.027249        0.027249              0.288637                0.288637  \n",
       "12      0.049500        0.049500              0.279538                0.279538  \n",
       "13      0.048316        0.048316              0.274193                0.274193  \n",
       "14      0.047693        0.047693              0.273785                0.273785  \n",
       "15      0.049430        0.049430              0.270043                0.270043  \n",
       "16      0.049325        0.049325              0.269702                0.269702  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot([2, 3, 4, 5, 6, 7, 8, 9, 10], [0.0069, 0.00628, 0.018615617, 0.015079936, 0.012565618, 0.012115437, 0.012049166, 0.011108142, 0.011183237], 'o-')\n",
    "plt.title('Logistic Regression - Opacity Score')\n",
    "plt.ylabel('Mean normalized trace cov. explanations matrix')\n",
    "plt.xlabel('Num. variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "num_vars = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "score = df_results_lr['mean_explanation_fit']\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot(num_vars, score, 'o-')\n",
    "plt.title('Logistic Regression - Opacity Score')\n",
    "plt.ylabel('Mean trace cov. explanations matrix')\n",
    "plt.xlabel('Num. variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "num_vars = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "score = [0.0138, 0.01886, 0.0744764, 0.075445792, 0.075410861, 0.084822101, 0.096375579, 0.099940218, 0.111810713, 0.1189631, 0.11911497, 0.120912857, 0.120802075, 0.133137306, 0.138690919, 0.138632272, 0.141359093]\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot(num_vars, score, 'o-')\n",
    "plt.title('Logistic Regression - Opacity Score')\n",
    "plt.ylabel('Mean trace cov. explanations matrix')\n",
    "plt.xlabel('Num. variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with  3  max_depth\n",
      "Iteration  0  of  1\n",
      "Train Accuracy: 0.769 - Train AUC: 0.769\n",
      "Test  Accuracy: 0.753 - Test AUC: 0.751\n",
      "[3]\n",
      "auc_train mean:  0.769\n",
      "auc_test mean:  0.753\n",
      "trace mean:  0.06102699287778197\n",
      "trace_normalized mean:  0.0030513496438890984\n",
      "median trace_normalized:  0.0030513496438890984\n",
      "mean max_eigenvalue:  0.028333855042091433\n",
      "explanation fit:  0.18661832435582576\n"
     ]
    }
   ],
   "source": [
    "l_max_depth = [3]#[2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "l_repetitions = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "results_dt = {}\n",
    "\n",
    "\n",
    "for i in range(len(l_max_depth)):\n",
    "    max_depth = l_max_depth[i]\n",
    "    n_reps = l_repetitions[i]\n",
    "    print('Starting with ', max_depth, ' max_depth')\n",
    "    results_dt[max_depth] = {}\n",
    "    results_dt[max_depth]['trace'] = []\n",
    "    results_dt[max_depth]['trace_normalized'] = []\n",
    "    results_dt[max_depth]['determinant'] = []\n",
    "    results_dt[max_depth]['determinant_normalized'] = []\n",
    "    results_dt[max_depth]['auc_train'] = []\n",
    "    results_dt[max_depth]['auc_test'] = []\n",
    "    results_dt[max_depth]['used_features'] = []\n",
    "    results_dt[max_depth]['max_depth'] = []\n",
    "    results_dt[max_depth]['max_eigenvalue'] = []\n",
    "    results_dt[max_depth]['explanation_fit'] = []\n",
    "    \n",
    "    for j in range(n_reps):\n",
    "        print('Iteration ', j, ' of ', n_reps)\n",
    "        \n",
    "        model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        model.fit(train, labels_train)\n",
    "        results_dt[max_depth]['max_depth'].append(model.tree_.max_depth) \n",
    "        acc_train, auc_train, acc_test, auc_test = evaluate_model(model, train, labels_train, test, labels_test, verbose=True)\n",
    "        results_dt[max_depth]['auc_train'].append(acc_train)\n",
    "        results_dt[max_depth]['auc_test'].append(acc_test)\n",
    "\n",
    "        # Create explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=feature_names, class_names=target_names, discretize_continuous=True)\n",
    "\n",
    "        # Explaining all samples\n",
    "        explanations_test, exp_score = obtain_explanations(explainer, model, test, feature_names)\n",
    "        np.savetxt(\"explanations_data/explanations_dt_\" + str(max_depth) + \"_\" + str(j)  + \".csv\", explanations_test, delimiter=\",\")\n",
    "        results_dt[max_depth]['explanation_fit'].append(np.mean(exp_score))\n",
    "\n",
    "        # Compute covariance matrix of Explanations datasets.\n",
    "        cov_matrix_test = np.cov(explanations_test, rowvar=False)\n",
    "        np.savetxt(\"results/cov_dt_\" + str(max_depth) + \"_\" + str(j)  + \".csv\", cov_matrix_test, delimiter=\",\")      \n",
    "\n",
    "        # Trace of covariance matrix\n",
    "        results_dt[max_depth]['trace'].append(np.trace(cov_matrix_test))\n",
    "        results_dt[max_depth]['trace_normalized'].append(np.trace(cov_matrix_test)/cov_matrix_test.shape[0])\n",
    "        results_dt[max_depth]['determinant'].append(np.linalg.det(cov_matrix_test))\n",
    "        results_dt[max_depth]['determinant_normalized'].append(np.linalg.det(cov_matrix_test)/cov_matrix_test.shape[0])\n",
    "        \n",
    "        # Eigenvalues\n",
    "        eigen_val, eigen_vectors = np.linalg.eig(cov_matrix_test)\n",
    "        results_dt[max_depth]['max_eigenvalue'].append(np.max(eigen_val))\n",
    "        \n",
    "    print(results_dt[max_depth]['max_depth'])\n",
    "    print('auc_train mean: ', np.mean(results_dt[max_depth]['auc_train']))\n",
    "    print('auc_test mean: ', np.mean(results_dt[max_depth]['auc_test']))\n",
    "    print('trace mean: ', np.mean(results_dt[max_depth]['trace']))\n",
    "    print('trace_normalized mean: ', np.mean(results_dt[max_depth]['trace_normalized']))\n",
    "    print('median trace_normalized: ', np.median(results_dt[max_depth]['trace_normalized']))\n",
    "    print('mean max_eigenvalue: ', np.mean(results_dt[max_depth]['max_eigenvalue']))\n",
    "    print('explanation fit: ', np.mean(results_dt[max_depth]['explanation_fit']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df and save df\n",
    "model_names = ['DT - ' + str(k) for k in l_max_depth]\n",
    "mean_auc_train = [np.mean(results_dt[k]['auc_train']) for k in l_max_depth]\n",
    "mean_auc_test = [np.mean(results_dt[k]['auc_test']) for k in l_max_depth]\n",
    "mean_trace = [np.mean(results_dt[k]['trace']) for k in l_max_depth]\n",
    "median_trace = [np.median(results_dt[k]['trace']) for k in l_max_depth]\n",
    "mean_trace_norm = [np.mean(results_dt[k]['trace_normalized']) for k in l_max_depth]\n",
    "mean_max_eig = [np.mean(results_dt[k]['max_eigenvalue']) for k in l_max_depth]\n",
    "median_max_eig = [np.median(results_dt[k]['max_eigenvalue']) for k in l_max_depth]\n",
    "mean_explanation_fit = [np.mean(results_dt[k]['explanation_fit']) for k in l_max_depth]\n",
    "median_explanation_fit = [np.median(results_dt[k]['explanation_fit']) for k in l_max_depth]\n",
    "\n",
    "df_results_dt = pd.DataFrame()\n",
    "df_results_dt['max_depth'] = l_max_depth\n",
    "df_results_dt['model_name'] = model_names\n",
    "df_results_dt['auc_train'] = mean_auc_train\n",
    "df_results_dt['auc_test'] = mean_auc_test\n",
    "df_results_dt['mean_trace'] = mean_trace\n",
    "df_results_dt['median_trace'] = median_trace\n",
    "df_results_dt['trace_norm'] = mean_trace_norm\n",
    "df_results_dt['mean_max_eig'] = mean_max_eig\n",
    "df_results_dt['median_max_eig'] = median_max_eig\n",
    "df_results_dt['mean_explanation_fit'] = mean_explanation_fit\n",
    "df_results_dt['median_explanation_fit'] = median_explanation_fit\n",
    "df_results_dt.to_csv('df_results_dt_maxdepth3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>mean_trace</th>\n",
       "      <th>median_trace</th>\n",
       "      <th>trace_norm</th>\n",
       "      <th>mean_max_eig</th>\n",
       "      <th>median_max_eig</th>\n",
       "      <th>mean_explanation_fit</th>\n",
       "      <th>median_explanation_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>DT - 3</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.061027</td>\n",
       "      <td>0.061027</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.186618</td>\n",
       "      <td>0.186618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth model_name  auc_train  auc_test  mean_trace  median_trace  \\\n",
       "0          3     DT - 3      0.769     0.753    0.061027      0.061027   \n",
       "\n",
       "   trace_norm  mean_max_eig  median_max_eig  mean_explanation_fit  \\\n",
       "0    0.003051      0.028334        0.028334              0.186618   \n",
       "\n",
       "   median_explanation_fit  \n",
       "0                0.186618  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>mean_trace</th>\n",
       "      <th>median_trace</th>\n",
       "      <th>trace_norm</th>\n",
       "      <th>mean_max_eig</th>\n",
       "      <th>median_max_eig</th>\n",
       "      <th>mean_explanation_fit</th>\n",
       "      <th>median_explanation_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>DT - 2</td>\n",
       "      <td>0.72825</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>0.189732</td>\n",
       "      <td>0.189732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>DT - 4</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.067557</td>\n",
       "      <td>0.067557</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.159078</td>\n",
       "      <td>0.159078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>DT - 6</td>\n",
       "      <td>0.87875</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.074078</td>\n",
       "      <td>0.074078</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>0.112860</td>\n",
       "      <td>0.112860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>DT - 8</td>\n",
       "      <td>0.92975</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.089358</td>\n",
       "      <td>0.089358</td>\n",
       "      <td>0.004468</td>\n",
       "      <td>0.026204</td>\n",
       "      <td>0.026204</td>\n",
       "      <td>0.099851</td>\n",
       "      <td>0.099851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>DT - 10</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.087945</td>\n",
       "      <td>0.087945</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.022747</td>\n",
       "      <td>0.022747</td>\n",
       "      <td>0.082671</td>\n",
       "      <td>0.082671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>DT - 12</td>\n",
       "      <td>0.98800</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.092019</td>\n",
       "      <td>0.092019</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.079674</td>\n",
       "      <td>0.079674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>DT - 14</td>\n",
       "      <td>0.99425</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.088827</td>\n",
       "      <td>0.088827</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.075596</td>\n",
       "      <td>0.075596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>DT - 16</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.025176</td>\n",
       "      <td>0.025176</td>\n",
       "      <td>0.078727</td>\n",
       "      <td>0.078727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>DT - 18</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.093409</td>\n",
       "      <td>0.093409</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>0.077845</td>\n",
       "      <td>0.077845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth model_name  auc_train  auc_test  mean_trace  median_trace  \\\n",
       "0          2     DT - 2    0.72825     0.723    0.042311      0.042311   \n",
       "1          4     DT - 4    0.79750     0.757    0.067557      0.067557   \n",
       "2          6     DT - 6    0.87875     0.821    0.074078      0.074078   \n",
       "3          8     DT - 8    0.92975     0.827    0.089358      0.089358   \n",
       "4         10    DT - 10    0.96775     0.838    0.087945      0.087945   \n",
       "5         12    DT - 12    0.98800     0.824    0.092019      0.092019   \n",
       "6         14    DT - 14    0.99425     0.836    0.088827      0.088827   \n",
       "7         16    DT - 16    0.99650     0.824    0.093545      0.093545   \n",
       "8         18    DT - 18    0.99925     0.821    0.093409      0.093409   \n",
       "\n",
       "   trace_norm  mean_max_eig  median_max_eig  mean_explanation_fit  \\\n",
       "0    0.002116      0.027455        0.027455              0.189732   \n",
       "1    0.003378      0.026865        0.026865              0.159078   \n",
       "2    0.003704      0.024192        0.024192              0.112860   \n",
       "3    0.004468      0.026204        0.026204              0.099851   \n",
       "4    0.004397      0.022747        0.022747              0.082671   \n",
       "5    0.004601      0.024383        0.024383              0.079674   \n",
       "6    0.004441      0.023500        0.023500              0.075596   \n",
       "7    0.004677      0.025176        0.025176              0.078727   \n",
       "8    0.004670      0.023235        0.023235              0.077845   \n",
       "\n",
       "   median_explanation_fit  \n",
       "0                0.189732  \n",
       "1                0.159078  \n",
       "2                0.112860  \n",
       "3                0.099851  \n",
       "4                0.082671  \n",
       "5                0.079674  \n",
       "6                0.075596  \n",
       "7                0.078727  \n",
       "8                0.077845  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot([2, 4, 6, 8, 10, 12, 14, 16, 17], [0.002141623, 0.0028, 0.003019607, 0.00323, 0.003348, 0.003374, 0.003318705, 0.003386327, 0.003397824] , 'o-')\n",
    "plt.title('Decision Tree - Opacity Score')\n",
    "plt.ylabel('Median normalized trace cov. explanations matrix')\n",
    "plt.xlabel('Max depth.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot([2, 4, 6, 8, 10, 12, 14, 16, 17], [0.042832462, 0.0574, 0.06039213, 0.06474, 0.06696, 0.06749, 0.066374093, 0.067726538, 0.067956477] , 'o-')\n",
    "plt.title('Decision Tree - Opacity Score')\n",
    "plt.ylabel('Trace cov. explanations matrix')\n",
    "plt.xlabel('Max depth.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees - AUC\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt_auc_train = [0.726875, 0.765, 0.8515625, 0.9259375, 0.9653, 0.9825, 0.9946875, 0.9990625, 1]\n",
    "df_auc_test = [0.69875, 0.7375, 0.78575, 0.80425, 0.80775, 0.8015, 0.8065, 0.8075, 0.8059375]\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "plt.plot([2, 4, 6, 8, 10, 12, 14, 16, 17], dt_auc_train , 'o-')\n",
    "plt.plot([2, 4, 6, 8, 10, 12, 14, 16, 17], df_auc_test, 'o-')\n",
    "plt.title('Decision Tree - Opacity Score')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Max depth.')\n",
    "plt.legend(['auc_train', 'auc_test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for  2\n",
      "auc_train mean:  0.8917460679370869\n",
      "auc_test mean:  0.797702055465971\n",
      "trace mean:  0.06531514905335616\n",
      "mean max_eigenvalue:  0.022749146256767615\n",
      "explanation fit:  0.12535610449225695\n",
      "-----------------------------\n",
      "Computing for  3\n",
      "auc_train mean:  0.9160028560456966\n",
      "auc_test mean:  0.8349265161912459\n",
      "trace mean:  0.05599724239080206\n",
      "mean max_eigenvalue:  0.018559037993238547\n",
      "explanation fit:  0.14096270704947464\n",
      "-----------------------------\n",
      "Computing for  5\n",
      "auc_train mean:  0.9406128498055969\n",
      "auc_test mean:  0.8630436261348677\n",
      "trace mean:  0.05474415732377598\n",
      "mean max_eigenvalue:  0.019196114911305618\n",
      "explanation fit:  0.17791732237674499\n",
      "-----------------------------\n",
      "Computing for  8\n",
      "auc_train mean:  0.9570127122033952\n",
      "auc_test mean:  0.8886159115553438\n",
      "trace mean:  0.05258099713100498\n",
      "mean max_eigenvalue:  0.015668283498688852\n",
      "explanation fit:  0.1991204714082555\n",
      "-----------------------------\n",
      "Computing for  12\n",
      "auc_train mean:  0.9641614265828252\n",
      "auc_test mean:  0.8942969522125169\n",
      "trace mean:  0.05411985767810314\n",
      "mean max_eigenvalue:  0.016116221159485696\n",
      "explanation fit:  0.2201536194249349\n",
      "-----------------------------\n",
      "Computing for  16\n",
      "auc_train mean:  0.9694201107217715\n",
      "auc_test mean:  0.9084567399837548\n",
      "trace mean:  0.05282545190606179\n",
      "mean max_eigenvalue:  0.016286139935039017\n",
      "explanation fit:  0.22895374449135925\n",
      "-----------------------------\n",
      "Computing for  20\n",
      "auc_train mean:  0.9721233539736636\n",
      "auc_test mean:  0.9138168766680405\n",
      "trace mean:  0.0527956256685362\n",
      "mean max_eigenvalue:  0.015520523267672342\n",
      "explanation fit:  0.2357275546267136\n",
      "-----------------------------\n",
      "Computing for  25\n",
      "auc_train mean:  0.9730675690811053\n",
      "auc_test mean:  0.9156066565567244\n",
      "trace mean:  0.05409116358896161\n",
      "mean max_eigenvalue:  0.016402017818076917\n",
      "explanation fit:  0.2428978617795868\n",
      "-----------------------------\n",
      "Computing for  30\n",
      "auc_train mean:  0.9742225875614009\n",
      "auc_test mean:  0.9125516667400237\n",
      "trace mean:  0.05264525915374516\n",
      "mean max_eigenvalue:  0.015210473179774694\n",
      "explanation fit:  0.2463736710174599\n",
      "-----------------------------\n",
      "Computing for  35\n",
      "auc_train mean:  0.9728715659450551\n",
      "auc_test mean:  0.9083467043322037\n",
      "trace mean:  0.053237741641834105\n",
      "mean max_eigenvalue:  0.015800149110987906\n",
      "explanation fit:  0.24809917705843582\n",
      "-----------------------------\n",
      "Computing for  40\n",
      "auc_train mean:  0.9739691835069362\n",
      "auc_test mean:  0.9200080826187685\n",
      "trace mean:  0.05157409624359567\n",
      "mean max_eigenvalue:  0.015084531076162967\n",
      "explanation fit:  0.2521110952474665\n",
      "-----------------------------\n",
      "Computing for  50\n",
      "auc_train mean:  0.9761708187330997\n",
      "auc_test mean:  0.9201829392723242\n",
      "trace mean:  0.05257356745174528\n",
      "mean max_eigenvalue:  0.015317202500271793\n",
      "explanation fit:  0.2539988894949593\n",
      "-----------------------------\n",
      "Computing for  60\n",
      "auc_train mean:  0.9769202307236917\n",
      "auc_test mean:  0.9197828096303203\n",
      "trace mean:  0.05169294453781442\n",
      "mean max_eigenvalue:  0.014961480003522301\n",
      "explanation fit:  0.25766628746950193\n",
      "-----------------------------\n",
      "Computing for  70\n",
      "auc_train mean:  0.9777178434854958\n",
      "auc_test mean:  0.9242202473601446\n",
      "trace mean:  0.05192389436996554\n",
      "mean max_eigenvalue:  0.014927160690237501\n",
      "explanation fit:  0.25770037130097095\n",
      "-----------------------------\n",
      "Computing for  80\n"
     ]
    }
   ],
   "source": [
    "max_depth = 8\n",
    "l_n_estimators = [2, 3, 5, 8, 12, 16, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_executions = 5\n",
    "results_rf2 = {}\n",
    "\n",
    "\n",
    "for n_estimators in l_n_estimators:\n",
    "    print('Computing for ', n_estimators)\n",
    "    results_rf2[n_estimators] = {}\n",
    "    results_rf2[n_estimators]['auc_train'] = []\n",
    "    results_rf2[n_estimators]['auc_test'] = []\n",
    "    results_rf2[n_estimators]['trace'] = []\n",
    "    results_rf2[n_estimators]['max_eigenvalue'] = []\n",
    "    results_rf2[n_estimators]['explanation_fit'] = []\n",
    "    \n",
    "    \n",
    "    for j in range(n_executions):\n",
    "        \n",
    "        model = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                                max_depth=max_depth, \n",
    "                                                min_samples_split=2,\n",
    "                                                min_samples_leaf=1\n",
    "                                                       )\n",
    "        model.fit(train, labels_train)\n",
    "\n",
    "        acc_train, auc_train, acc_test, auc_test = evaluate_model(model, train, labels_train, test, labels_test, verbose=False)\n",
    "\n",
    "        # Create explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=feature_names, class_names=target_names, discretize_continuous=True)\n",
    "\n",
    "        # Explaining all samples\n",
    "        explanations_test, exp_score = obtain_explanations(explainer, model, test, feature_names)\n",
    "        np.savetxt(\"explanations_data/explanations_rf_\" + str(n_estimators) + \"_\" + str(j)  + \".csv\", explanations_test, delimiter=\",\")      \n",
    "\n",
    "        # Compute covariance matrix of Explanations datasets.\n",
    "        cov_matrix_test = np.cov(explanations_test, rowvar=False)\n",
    "        np.savetxt(\"results/cov_rf_\" + str(n_estimators) + \"_\" + str(j)  + \".csv\", cov_matrix_test, delimiter=\",\")\n",
    "\n",
    "        # Compute eigenvalues and eigenvectors of covariance matrix\n",
    "        eigen_val, eigen_vectors = np.linalg.eig(cov_matrix_test)\n",
    "\n",
    "        # Add results\n",
    "        results_rf2[n_estimators]['auc_train'].append(auc_train)\n",
    "        results_rf2[n_estimators]['auc_test'].append(auc_test)\n",
    "        results_rf2[n_estimators]['trace'].append(np.trace(cov_matrix_test))\n",
    "        results_rf2[n_estimators]['max_eigenvalue'].append(np.max(eigen_val))\n",
    "        results_rf2[n_estimators]['explanation_fit'].append(np.mean(exp_score))\n",
    "        \n",
    "\n",
    "    print('auc_train mean: ', np.mean(results_rf2[n_estimators]['auc_train']))\n",
    "    print('auc_test mean: ', np.mean(results_rf2[n_estimators]['auc_test']))\n",
    "    print('trace mean: ', np.mean(results_rf2[n_estimators]['trace']))\n",
    "    print('mean max_eigenvalue: ', np.mean(results_rf2[n_estimators]['max_eigenvalue']))\n",
    "    print('explanation fit: ', np.mean(results_rf2[n_estimators]['explanation_fit']))\n",
    "    print('-----------------------------')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df and save df\n",
    "model_names = ['RF - 3 max_depth - ' + str(k) + ' trees' for k in l_n_estimators]\n",
    "mean_auc_train = [np.mean(results_rf2[k]['auc_train']) for k in l_n_estimators]\n",
    "mean_auc_test = [np.mean(results_rf2[k]['auc_test']) for k in l_n_estimators]\n",
    "mean_trace = [np.mean(results_rf2[k]['trace']) for k in l_n_estimators]\n",
    "median_trace = [np.median(results_rf2[k]['trace']) for k in l_n_estimators]\n",
    "mean_max_eig = [np.mean(results_rf2[k]['max_eigenvalue']) for k in l_n_estimators]\n",
    "median_max_eig = [np.median(results_rf2[k]['max_eigenvalue']) for k in l_n_estimators]\n",
    "mean_explanation_fit = [np.mean(results_rf2[k]['explanation_fit']) for k in l_n_estimators]\n",
    "median_explanation_fit = [np.median(results_rf2[k]['explanation_fit']) for k in l_n_estimators]\n",
    "\n",
    "df_results_rf2 = pd.DataFrame()\n",
    "df_results_rf2['max_depth'] = l_n_estimators\n",
    "df_results_rf2['model_name'] = model_names\n",
    "df_results_rf2['auc_train'] = mean_auc_train\n",
    "df_results_rf2['auc_test'] = mean_auc_test\n",
    "df_results_rf2['mean_trace'] = mean_trace\n",
    "df_results_rf2['median_trace'] = median_trace\n",
    "df_results_rf2['mean_max_eig'] = mean_max_eig\n",
    "df_results_rf2['median_max_eig'] = median_max_eig\n",
    "df_results_rf2['mean_explanation_fit'] = mean_explanation_fit\n",
    "df_results_rf2['median_explanation_fit'] = median_explanation_fit\n",
    "df_results_rf2.to_csv('df_results_rf_max_depth8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "rt_n_estimators = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "rt_opacity_score_1 = [0.023719672, 0.020162563, 0.013179423, 0.018304094, 0.017342572, 0.015894145, 0.017758619, 0.016590274, 0.015305451]\n",
    "rt_opacity_score_2 = [0.040151616, 0.046891136, 0.043122655, 0.041279204, 0.040748781, 0.040559727, 0.038958451, 0.045356865, 0.048994338]\n",
    "plt.plot(rt_n_estimators, rt_opacity_score_1 , 'o-')\n",
    "plt.plot(rt_n_estimators, rt_opacity_score_2 , 'o-')\n",
    "plt.title('Random Forest - Opacity Score')\n",
    "plt.ylabel('Trace cov. explanations matrix')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.legend(['max_depth = 3', 'max_depth = 8'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarize data (also try without scaling)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train)\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for  (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_train mean:  0.996898750380006\n",
      "auc_test mean:  0.9695181238721347\n",
      "trace mean:  0.16525267687869888\n",
      "mean max_eigenvalue:  0.044858476267710085\n",
      "explanation fit:  0.19591269843705408\n",
      "-----------------------------\n",
      "Computing for  (100, 100)\n",
      "auc_train mean:  1.0\n",
      "auc_test mean:  0.9627663362929588\n",
      "trace mean:  0.1562439745226606\n",
      "mean max_eigenvalue:  0.04169596736821722\n",
      "explanation fit:  0.15667930386267265\n",
      "-----------------------------\n",
      "Computing for  (100, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "#architectures = [(10,), (20,), (30,), (40,), (50,), (60,), (70,), (80,), (90,), (100,)]\n",
    "architectures = [(100,), (100,100,), (100,100,100,), (100,100,100,100,), (100,100,100,100,100), \n",
    "                 (100,100,100,100,100,100), (100,100,100,100,100,100,100), (100,100,100,100,100,100,100,100)]\n",
    "n_executions = 5\n",
    "results_nn8 = {}\n",
    "\n",
    "train_use = train\n",
    "test_use = test\n",
    "\n",
    "for architecture in architectures:\n",
    "    print('Computing for ', architecture)\n",
    "    results_nn8[architecture] = {}\n",
    "    results_nn8[architecture]['auc_train'] = []\n",
    "    results_nn8[architecture]['auc_test'] = []\n",
    "    results_nn8[architecture]['trace'] = []\n",
    "    results_nn8[architecture]['max_eigenvalue'] = []\n",
    "    results_nn8[architecture]['explanation_fit'] = []\n",
    "    \n",
    "    \n",
    "    for j in range(n_executions):\n",
    "        \n",
    "        model = MLPClassifier(hidden_layer_sizes=architecture, \n",
    "                  activation='logistic', \n",
    "                  solver='adam', \n",
    "                  alpha=0.0001, \n",
    "                  batch_size=128, \n",
    "                  learning_rate='constant', \n",
    "                  learning_rate_init=0.001,  \n",
    "                  max_iter=200, \n",
    "                  shuffle=True, \n",
    "                  #random_state=1, \n",
    "                  tol=0.0001, \n",
    "                  verbose=False, \n",
    "                  momentum=0.9, # Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=sgd.\n",
    "                  nesterovs_momentum=True, \n",
    "                  early_stopping=False, \n",
    "                  validation_fraction=0.1, \n",
    "                  beta_1=0.9,\n",
    "                  beta_2=0.999, \n",
    "                  epsilon=1e-08)\n",
    "        \n",
    "        model.fit(train_use, labels_train)\n",
    "\n",
    "        acc_train, auc_train, acc_test, auc_test = evaluate_model(model, train_use, labels_train, test_use, labels_test, verbose=False)\n",
    "\n",
    "        # Create explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(train_use, feature_names=feature_names, class_names=target_names, discretize_continuous=True)\n",
    "\n",
    "        # Explaining all samples\n",
    "        explanations_test, exp_score = obtain_explanations(explainer, model, test_use, feature_names)\n",
    "        np.savetxt(\"explanations_data/explanations_nn8_\" + str(architecture) + \"_notscaling_tanh_\" + str(j)  + \".csv\", explanations_test, delimiter=\",\")      \n",
    "\n",
    "        # Compute covariance matrix of Explanations datasets.\n",
    "        cov_matrix_test = np.cov(explanations_test, rowvar=False)\n",
    "        np.savetxt(\"results/cov_nn7_\" + str(architecture) + \"_tanh_\" + str(j)  + \".csv\", cov_matrix_test, delimiter=\",\")\n",
    "\n",
    "        # Compute eigenvalues and eigenvectors of covariance matrix\n",
    "        eigen_val, eigen_vectors = np.linalg.eig(cov_matrix_test)\n",
    "\n",
    "        # Add results\n",
    "        results_nn8[architecture]['auc_train'].append(auc_train)\n",
    "        results_nn8[architecture]['auc_test'].append(auc_test)\n",
    "        results_nn8[architecture]['trace'].append(np.trace(cov_matrix_test))\n",
    "        results_nn8[architecture]['max_eigenvalue'].append(np.max(eigen_val))\n",
    "        results_nn8[architecture]['explanation_fit'].append(np.mean(exp_score))\n",
    "        \n",
    "\n",
    "    print('auc_train mean: ', np.mean(results_nn8[architecture]['auc_train']))\n",
    "    print('auc_test mean: ', np.mean(results_nn8[architecture]['auc_test']))\n",
    "    print('trace mean: ', np.mean(results_nn8[architecture]['trace']))\n",
    "    print('mean max_eigenvalue: ', np.mean(results_nn8[architecture]['max_eigenvalue']))\n",
    "    print('explanation fit: ', np.mean(results_nn8[architecture]['explanation_fit']))\n",
    "    print('-----------------------------')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df and save df\n",
    "model_names = ['NN - ' + str(k) for k in architectures]\n",
    "mean_auc_train = [np.mean(results_nn8[k]['auc_train']) for k in architectures]\n",
    "mean_auc_test = [np.mean(results_nn8[k]['auc_test']) for k in architectures]\n",
    "mean_trace = [np.mean(results_nn8[k]['trace']) for k in architectures]\n",
    "median_trace = [np.median(results_nn8[k]['trace']) for k in architectures]\n",
    "mean_max_eig = [np.mean(results_nn8[k]['max_eigenvalue']) for k in architectures]\n",
    "median_max_eig = [np.median(results_nn8[k]['max_eigenvalue']) for k in architectures]\n",
    "mean_explanation_fit = [np.mean(results_nn8[k]['explanation_fit']) for k in architectures]\n",
    "median_explanation_fit = [np.median(results_nn8[k]['explanation_fit']) for k in architectures]\n",
    "\n",
    "df_results_nn8 = pd.DataFrame()\n",
    "#results_nn['layer_spec'] = model_names\n",
    "df_results_nn8['model_name'] = model_names\n",
    "df_results_nn8['auc_train'] = mean_auc_train\n",
    "df_results_nn8['auc_test'] = mean_auc_test\n",
    "df_results_nn8['mean_trace'] = mean_trace\n",
    "df_results_nn8['median_trace'] = median_trace\n",
    "df_results_nn8['mean_max_eig'] = mean_max_eig\n",
    "df_results_nn8['median_max_eig'] = median_max_eig\n",
    "df_results_nn8['mean_explanation_fit'] = mean_explanation_fit\n",
    "df_results_nn8['median_explanation_fit'] = median_explanation_fit\n",
    "df_results_nn8.to_csv('df_results_nn_N_layers_no_scaling_tanh.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
